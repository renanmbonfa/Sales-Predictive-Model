---
title: "TRABALHO - APA.rmd"
author: "Renan Bonfá"
date: "20/11/2021"
output:
  word_document: default
  html_document: default
---


# Tratamento dos dados

```{r}
#IMPORTANDO BIBLIOTECAS 2
options(warn=-1)

library(broom)
library(corrplot)
library(caret)
library(mlbench)
library(glmnet)
library(GA)
library(dplyr)
library(doParallel)
library(ggplot2)
library(glmnet)
library(xgboost)
library(kernlab)
```

```{r}
#Leitura arquivo

setwd("~/R Projects/APA - IND/Dataset")
df <- read.csv(file = "Retail.csv", sep =",", dec = ",")
```

```{r}
#Avaliar dados
head(df,10)
summary(df)
```

### Transformando váriaveis
```{r}
ncol(df)

#Transformando var caracteres em numericas
df$Temperature <- as.numeric(df$Temperature)
df$Fuel_Price <- as.numeric(df$Fuel_Price)
df$MarkDown1 <- as.numeric(df$MarkDown1)
df$MarkDown2 <- as.numeric(df$MarkDown2)
df$MarkDown3 <- as.numeric(df$MarkDown3)
df$MarkDown4 <- as.numeric(df$MarkDown4)
df$MarkDown5 <- as.numeric(df$MarkDown5)
df$CPI <- as.numeric(df$CPI)
df$Unemployment <- as.numeric(df$Unemployment)
df$Weekly_Sales <- as.numeric(df$Weekly_Sales)

#Data
df$Date <- as.Date(df$Date)

#Tranformando as var categoricas em fatores
df$Store <- as.factor(df$Store)
df$IsHoliday <- as.factor(df$IsHoliday)

#revisando  
head(df)
summary(df)
```

### Boxplosts e Histogramas 
**Verificação da distribuição dos dados**
```{r}
#Boxplots e Histogramas
colnames(df)
head(df)

#Table (df$Store)
table(df$Store)

#Boxplot e Histograma (df$Temperature)
par(mfrow = c(1,2))
boxplot(df$Temperature,main = "Boxplot - df$Temperature")
hist(df$Temperature)

#Boxplot e Histograma (df$Fuel_Price)
par(mfrow = c(1,2))
boxplot(df$Fuel_Price, main = "Boxplot - df$Fuel_Price")
hist(df$Fuel_Price)

#Boxplot e Histograma (df$Mardown1)
par(mfrow = c(1,2))
boxplot(df$MarkDown1, main = "Boxplot - df$Markdown1")
hist(df$MarkDown1)

#Boxplot e Histograma (df$Markdown2)
par(mfrow = c(1,2))
boxplot(df$MarkDown2, main = "Boxplot - df$Markdown2")
hist(df$MarkDown2)

#Boxplot e Histograma (df$Markdown3)
par(mfrow = c(1,2))
boxplot(df$MarkDown3, main = "Boxplot - df$Markdown3")
hist(df$MarkDown3)

#Boxplot e Histograma (df$Markdown4)
par(mfrow = c(1,2))
boxplot(df$MarkDown4, main = "Boxplot - df$Markdown4")
hist(df$MarkDown4)

#Boxplot e Histograma (df$Markdown5)
par(mfrow = c(1,2))
boxplot(df$MarkDown5, main = "Boxplot - df$Markdown5")
hist(df$MarkDown5)

#Boxplot e Histograma (df$CPI)
par(mfrow = c(1,2))
boxplot(df$CPI, main = "Boxplot - df$CPI")
hist(df$CPI)

#Boxplot e Histograma (df$Unemployment)
par(mfrow = c(1,2))
boxplot(df$Unemployment, main = "Boxplot - df$Unemployment")
hist(df$Unemployment)

#Table(df$IsHoliday)
table(df$IsHoliday)

#Boxplot e Histograma (df$Weekly_Sales)
par(mfrow = c(1,2))
boxplot(df$Weekly_Sales, main = "Boxplot - df$Weekly_Sales")
hist(df$Weekly_Sales)
```

### Percentual de NAs por coluna
```{r}
#missing data por colunas

md_df <- for(i in 1:length(df)) {
  print(paste(colnames(df[i]),
              "possui % de NAs de",
              round(sum(is.na(df[ ,i]))/nrow(df),2)))
  
}


```

### Redefinindo NAs
```{r}
#Como nas Variáveis Mardown 1-5 os dados estão mal distribuídos, atribuí aos valores NA
# a mediana, para cada variável respectiva.

df$MarkDown1[is.na(df$MarkDown1)] <- median(df$MarkDown1, na.rm = TRUE)
df$MarkDown2[is.na(df$MarkDown2)] <- median(df$MarkDown2, na.rm = TRUE)
df$MarkDown3[is.na(df$MarkDown3)] <- median(df$MarkDown3, na.rm = TRUE)
df$MarkDown4[is.na(df$MarkDown4)] <- median(df$MarkDown4, na.rm = TRUE)
df$MarkDown5[is.na(df$MarkDown5)] <- median(df$MarkDown5, na.rm = TRUE)

#Decidi rejeitar os NAs de CPI e Unemployment por serem menos reprensentativos no dataset
#Sumindo com os NAs de CPI,os NAs de Unemployment somem automaticamente, pois são os mesmos

df <- subset(df, CPI != "NA")

#Var preditiva se aproxima mais de uma distribuição normal. Por isso, atribui os valores
# NA a media dos valores

df$Weekly_Sales[is.na(df$Weekly_Sales)] <- mean(df$Weekly_Sales, na.rm = TRUE)

#Verificação de NAs
colSums(is.na(df))
```

### CORR-PLOT- Matriz de correlação
```{r}
#CORR-PLOT
MC <- cor(df[ ,c(-1,-2,-12)])

PLOT <- corrplot(corr = MC,
                 method = "square",
                 type = "full",
                 tl.cex = 0.8,
                 tl.col = "black",
                 tl.offset = 1,
                 tl.srt = 45,
                 cl.offset  = 1,
                 addCoef.col = "black",
                 number.cex = 0.7)
```

### Separandos os dados
```{r}
set.seed(314)

trainIndex <- createDataPartition(df$Weekly_Sales, p = .7, list = FALSE)

set.seed(314)
dfTrain <- df[ trainIndex,]
dfTest  <- df[-trainIndex,]

summary(df)
```

# Implementação dos modelos

## REGRESSÃO LINEAR - MODELO 1**
```{r}
#cross-validation (nem usei)
cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, classProbs = FALSE)
```

```{r}
set.seed(314)

model_reglin <- train(Weekly_Sales~., data = dfTrain ,method = "lm", trControl = cv)

model_reglin
```

### IMPORTANCE - LINEAR MODEL**
```{r}
#Importance
imp <- varImp(model_reglin, useModel=FALSE, scale=FALSE)
imp
plot(imp)
```

### SCORING - LINEAR MODEL**
```{r}
pred_Model_reglin <- predict(model_reglin, dfTest)
dfTest$Model_reglin <- pred_Model_reglin
head(dfTest)
```

## ÁRVORES DE DECISÃO
```{r}
#cross-validation
cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, classProbs = FALSE)
```

### BAGGING -MODELO 2
```{r}
set.seed(314)

model_bagging <- train(Weekly_Sales~. , data = dfTrain, method = "treebag",trControl = cv)

model_bagging
```

#### IMPORTANCE
```{r}
imp_bagging <- varImp(model_bagging, useModel=FALSE, scale=FALSE)
imp_bagging
plot(imp_bagging)
```

### BOOSTING - MODELO 3
```{r}
set.seed(314)

model_boosting <- train(Weekly_Sales~. , data = dfTrain, method = "xgbTree",trControl = cv)

model_boosting
```

#### IMPORTANCE
```{r}
#Importance
imp_boosting <- varImp(model_boosting, useModel=FALSE, scale=FALSE)
imp_boosting
plot(imp_boosting)
```

### RANDOM FOREST- MODELO 4
```{r}
set.seed(314)

model_rf <- train(Weekly_Sales~. , data = dfTrain, method = "rf",trControl = cv)

model_rf

#Importance
imp_rf <- varImp(model_rf, useModel=FALSE, scale=FALSE)
imp_rf
plot(imp_rf)
```

### Scoring dos 3 modelos de Decision Trees
```{r}
#Scoring dos 3 modelos acima
pred_bagging <- predict(model_bagging ,newdata=dfTest)
dfTest$Model_DT_bagging <- pred_bagging

pred_boosting <- predict(model_boosting ,newdata=dfTest)
dfTest$Model_DT_boosting <- pred_boosting

pred_rf <- predict(model_rf ,newdata=dfTest)
dfTest$Model_DT_rf <- pred_rf

#Head - Scoring 
head(dfTest,10)
```

## SUPPORT VECTOR MACHINE
```{r}
options(warn=-1)

cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
```

### SVM - Linear Kernel - MODELO 5
```{r}
model_SVM_LK <- train(Weekly_Sales~., data = dfTrain, method = "svmLinear", trControl = cv,  preProcess = c("center", "scale"))

model_SVM_LK
```

#### IMPORTANCE
```{r}
imp_SVM_LK <- varImp(model_SVM_LK, useModel=FALSE, scale=FALSE)
imp_SVM_LK
plot(imp_SVM_LK)
```

### SVM - RBF Kernel- MODELO 6
```{r}
options(warn=-1)


model_SVM_rbf <- train(Weekly_Sales~., data = dfTrain, method = "svmRadial", trControl = cv, preProcess = c("center", "scale"))

model_SVM_rbf
```

#### IMPORTANCE
```{r}
imp_SVM_rbf <- varImp(model_SVM_rbf, useModel=FALSE, scale=FALSE)
imp_SVM_rbf
plot(imp_SVM_rbf)
```

### Scoring dos 2 modelos de SVM
```{r}
pred_SVM_LK <- predict(model_SVM_LK, newdata=dfTest)
dfTest$Model_SVM_LK <- pred_SVM_LK

pred_SVM_rbf <- predict(model_SVM_rbf, newdata=dfTest)
dfTest$Model_SVM_rbf <- pred_SVM_rbf

#Head - Scoring 
head(dfTest,10)
```

## ALGORITMOS GENÉTICOS - MODELO 7
```{r}
registerDoParallel(4) 
getDoParWorkers() 

set.seed(314)
ctrl <- gafsControl(functions = caretGA,
                    genParallel=TRUE,
                    allowParallel=TRUE,
                    method = "cv")


Model_AG <- gafs(x = dfTrain[ ,-ncol(df)],
            y = dfTrain$Weekly_Sales,
            iters = 2,
            popSize = 2,
            gafsControl = ctrl,
            method = "lm")

Model_AG
```

```{r}
final <- Model_AG$ga$final

final
```

## Scoring - AG
```{r}
pred_AG <- predict(Model_AG ,newdata = dfTest)
dfTest$Model_AG <- pred_AG

#Head - Scoring 
head(dfTest,10)
```

# Conclusões



Após tratar o dataset e executar os modelos, observei que obtive resultados relativamente próximos para os modelos de regressão linear, SVM e Algoritmos Genéticos. 

No caso da regressão linear, tentei fazer regularização Lasso e Ridge, porém não obtive bons resultados, por isso optei por deixar no trabalho a regressão linear com cross-validation sem regularização.

O principal parâmetro para selecionar o meu melhor modelo foi o Rsquared (R²), que indica a porcentagem da variância na variável dependente que as variáveis independentes explicam coletivamente. Rsquared mede a força da relação entre seu modelo e a variável dependente em uma escala conveniente de 0 a 100%.  

Em um segundo plano, também levei em consideração a RMSE. Root Mean Square Error (RMSE) é o desvio padrão dos resíduos (erros de predição). Resíduos medem quão longe os pontos de dados da linha de regressão estão.

O RMSE é uma medida de quão espalhados são esses resíduos. Em outras palavras, o RMSE informa o quão concentrados os dados estão em torno da linha de melhor ajuste. Números menores são melhores, com zero sendo um ajuste perfeito para os dados. Vale ressaltar que tanto Rsquared e RMSE avaliam a acurácia do modelo.

Tomando o Rsquared como principal métrica para análise de performance de modelo, o modelo que apresentou melhores resultados foi o Modelo 3 (Árvores de Decisão com Boosting) com Rsquared de 0.9372519 e RMSE de 129846.3.




