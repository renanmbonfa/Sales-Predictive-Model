---
title: "APA2"
author: "Renan Bonfá"
date: "20/11/2021"
output:
  word_document: default
  html_document: default
---
# Data processing

```{r}
# IMPORTING LIBRARIES 2

options(warn=-1)
library(broom)
library(corrplot)
library(caret)
library(mlbench)
library(glmnet)
library(GA)
library(dplyr)
library(doParallel)
library(ggplot2)
library(glmnet)
library(xgboost)
library(kernlab)
```

```{r}
#Read file

setwd("~/R Projects/APA - IND/Dataset")
df <- read.csv(file = "Retail.csv", sep =",", dec = ",")
```

```{r}
# Evaluate data
head(df,10)
summary(df)
```

### Transforming variables
```{r}
ncol(df)

# Converting var characters to numeric
df$Temperature <- as.numeric(df$Temperature)
df$Fuel_Price <- as.numeric(df$Fuel_Price)
df$MarkDown1 <- as.numeric(df$MarkDown1)
df$MarkDown2 <- as.numeric(df$MarkDown2)
df$MarkDown3 <- as.numeric(df$MarkDown3)
df$MarkDown4 <- as.numeric(df$MarkDown4)
df$MarkDown5 <- as.numeric(df$MarkDown5)
df$CPI <- as.numeric(df$CPI)
df$Unemployment <- as.numeric(df$Unemployment)
df$Weekly_Sales <- as.numeric(df$Weekly_Sales)

#Date
df$Date <- as.Date(df$Date)

#Turning categorical vars into factors
df$Store <- as.factor(df$Store)
df$IsHoliday <- as.factor(df$IsHoliday)

# reviewing
head(df)
summary(df)
```

### Boxplosts and Histograms
**Verification of data distribution**
```{r}
#Boxplots and Histograms
columns(df)
head(df)

#Table (df$Store)
table(df$Store)

#Boxplot and Histogram (df$Temperature)
par(mfrow = c(1,2))
boxplot(df$Temperature,main = "Boxplot - df$Temperature")
hist(df$Temperature)

#Boxplot and Histogram (df$Fuel_Price)
par(mfrow = c(1,2))
boxplot(df$Fuel_Price, main = "Boxplot - df$Fuel_Price")
hist(df$Fuel_Price)

#Boxplot and Histogram (df$Mardown1)
par(mfrow = c(1,2))
boxplot(df$MarkDown1, main = "Boxplot - df$Markdown1")
hist(df$MarkDown1)

#Boxplot and Histogram (df$Markdown2)
par(mfrow = c(1,2))
boxplot(df$MarkDown2, main = "Boxplot - df$Markdown2")
hist(df$MarkDown2)

#Boxplot and Histogram (df$Markdown3)
par(mfrow = c(1,2))
boxplot(df$MarkDown3, main = "Boxplot - df$Markdown3")
hist(df$MarkDown3)

#Boxplot and Histogram (df$Markdown4)
par(mfrow = c(1,2))
boxplot(df$MarkDown4, main = "Boxplot - df$Markdown4")
hist(df$MarkDown4)

#Boxplot and Histogram (df$Markdown5)
par(mfrow = c(1,2))
boxplot(df$MarkDown5, main = "Boxplot - df$Markdown5")
hist(df$MarkDown5)

#Boxplot and Histogram (df$CPI)
par(mfrow = c(1,2))
boxplot(df$CPI, main = "Boxplot - df$CPI")
hist(df$CPI)

#Boxplot and Histogram (df$Unemployment)
par(mfrow = c(1,2))
boxplot(df$Unemployment, main = "Boxplot - df$Unemployment")
hist(df$Unemployment)

#Table(df$IsHoliday)
table(df$IsHoliday)

#Boxplot and Histogram (df$Weekly_Sales)
par(mfrow = c(1,2))
boxplot(df$Weekly_Sales, main = "Boxplot - df$Weekly_Sales")
hist(df$Weekly_Sales)
```

### Percentage of NAs per column
```{r}
#missing data by columns

md_df <- for(i in 1:length(df)) {
   print(paste(colnames(df[i]),
               "has % of NAs of",
               round(sum(is.na(df[,i]))/nrow(df),2)))
  
}

```

### Redefining NAs
```{r}
#As in Mardown Variables 1-5 the data are poorly distributed, I assigned the NA values
# the median, for each respective variable.

df$MarkDown1[is.na(df$MarkDown1)] <- median(df$MarkDown1, na.rm = TRUE)
df$MarkDown2[is.na(df$MarkDown2)] <- median(df$MarkDown2, na.rm = TRUE)
df$MarkDown3[is.na(df$MarkDown3)] <- median(df$MarkDown3, na.rm = TRUE)
df$MarkDown4[is.na(df$MarkDown4)] <- median(df$MarkDown4, na.rm = TRUE)
df$MarkDown5[is.na(df$MarkDown5)] <- median(df$MarkDown5, na.rm = TRUE)

#I decided to reject the CPI and Unemployment NAs as they are less representative in the dataset
# By disappearing with the CPI NAs, the Unemployment NAs automatically disappear, as they are the same

df <- subset(df, CPI != "NA")

#Var predictive more closely approximates a normal distribution. Therefore, assign the values
# NA the average of the values

df$Weekly_Sales[is.na(df$Weekly_Sales)] <- mean(df$Weekly_Sales, na.rm = TRUE)

# NA verification
colSums(is.na(df))
```

### CORR-PLOT- Correlation matrix
```{r}
#CORR-PLOT
MC <- cor(df[ ,c(-1,-2,-12)])

PLOT <- corrplot(corr = MC,
                 method = "square",
                 type = "full",
                 tl.cex = 0.8,
                 tl.col = "black",
                 tl.offset = 1,
                 tl.srt = 45,
                 cl.offset  = 1,
                 addCoef.col = "black",
                 number.cex = 0.7)
```

### Separating the data
```{r}
set.seed(314)

trainIndex <- createDataPartition(df$Weekly_Sales, p = .7, list = FALSE)

set.seed(314)
dfTrain <- df[ trainIndex,]
dfTest  <- df[-trainIndex,]

summary(df)
```

# Implementation of models

## LINEAR REGRESSION - MODEL 1**
```{r}
#cross-validation 
cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, classProbs = FALSE)
```

```{r}
set.seed(314)

model_reglin <- train(Weekly_Sales~., data = dfTrain ,method = "lm", trControl = cv)

model_reglin
```

### IMPORTANCE - LINEAR MODEL**
```{r}
#Importance
imp <- varImp(model_reglin, useModel=FALSE, scale=FALSE)
imp
plot(imp)
```

### SCORING - LINEAR MODEL**
```{r}
pred_Model_reglin <- predict(model_reglin, dfTest)
dfTest$Model_reglin <- pred_Model_reglin
head(dfTest)
```

## DECISION TREES
```{r}
#cross-validation
cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, classProbs = FALSE)
```

### BAGGING -MODEL 2
```{r}
set.seed(314)

model_bagging <- train(Weekly_Sales~. , data = dfTrain, method = "treebag",trControl = cv)

model_bagging
```

#### IMPORTANCE
```{r}
imp_bagging <- varImp(model_bagging, useModel=FALSE, scale=FALSE)
imp_bagging
plot(imp_bagging)
```

### BOOSTING - MODEL 3
```{r}
set.seed(314)

model_boosting <- train(Weekly_Sales~. , data = dfTrain, method = "xgbTree",trControl = cv)

model_boosting
```

#### IMPORTANCE
```{r}
#Importance
imp_boosting <- varImp(model_boosting, useModel=FALSE, scale=FALSE)
imp_boosting
plot(imp_boosting)
```

### RANDOM FOREST- MODEL 4
```{r}
set.seed(314)

model_rf <- train(Weekly_Sales~. , data = dfTrain, method = "rf",trControl = cv)

model_rf

#Importance
imp_rf <- varImp(model_rf, useModel=FALSE, scale=FALSE)
imp_rf
plot(imp_rf)
```

### Scoring of the 3 Decision Trees models
```{r}
#Scoring of the 3 models above
pred_bagging <- predict(model_bagging ,newdata=dfTest)
dfTest$Model_DT_bagging <- pred_bagging

pred_boosting <- predict(model_boosting ,newdata=dfTest)
dfTest$Model_DT_boosting <- pred_boosting

pred_rf <- predict(model_rf ,newdata=dfTest)
dfTest$Model_DT_rf <- pred_rf

#Head - Scoring 
head(dfTest,10)
```

## SUPPORT VECTOR MACHINE
```{r}
options(warn=-1)

cv <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
```

### SVM - Linear Kernel - MODEL 5
```{r}
model_SVM_LK <- train(Weekly_Sales~., data = dfTrain, method = "svmLinear", trControl = cv,  preProcess = c("center", "scale"))

model_SVM_LK
```

#### IMPORTANCE
```{r}
imp_SVM_LK <- varImp(model_SVM_LK, useModel=FALSE, scale=FALSE)
imp_SVM_LK
plot(imp_SVM_LK)
```

### SVM - RBF Kernel- MODEL 6
```{r}
options(warn=-1)


model_SVM_rbf <- train(Weekly_Sales~., data = dfTrain, method = "svmRadial", trControl = cv, preProcess = c("center", "scale"))

model_SVM_rbf
```

#### IMPORTANCE
```{r}
imp_SVM_rbf <- varImp(model_SVM_rbf, useModel=FALSE, scale=FALSE)
imp_SVM_rbf
plot(imp_SVM_rbf)
```

### Scoring of the 2 SVM models
```{r}
pred_SVM_LK <- predict(model_SVM_LK, newdata=dfTest)
dfTest$Model_SVM_LK <- pred_SVM_LK

pred_SVM_rbf <- predict(model_SVM_rbf, newdata=dfTest)
dfTest$Model_SVM_rbf <- pred_SVM_rbf

#Head - Scoring 
head(dfTest,10)
```

## GENETIC ALGORITHMS - MODEL 7
```{r}
registerDoParallel(4) 
getDoParWorkers() 

set.seed(314)
ctrl <- gafsControl(functions = caretGA,
                    genParallel=TRUE,
                    allowParallel=TRUE,
                    method = "cv")


Model_AG <- gafs(x = dfTrain[ ,-ncol(df)],
            y = dfTrain$Weekly_Sales,
            iters = 2,
            popSize = 2,
            gafsControl = ctrl,
            method = "lm")

Model_AG
```

```{r}
final <- Model_AG$ga$final

final
```

## Scoring - AG
```{r}
pred_AG <- predict(Model_AG ,newdata = dfTest)
dfTest$Model_AG <- pred_AG

#Head - Scoring 
head(dfTest,10)
```

# Conclusions



After treating the dataset and running the models, I observed that I obtained relatively close results for the linear regression, SVM and Genetic Algorithms models.

In the case of linear regression, I tried to do Lasso and Ridge regularization, but I did not get good results, so I chose to leave linear regression with cross-validation without regularization at work.

The main parameter for selecting my best model was the Rsquared (R²), which indicates the percentage of variance in the dependent variable that the independent variables collectively explain. Rsquared measures the strength of the relationship between your model and the dependent variable on a convenient scale from 0 to 100%.

In the background, I also took into account the RMSE. Root Mean Square Error (RMSE) is the standard deviation of residuals (prediction errors). Residuals measure how far the data points are from the regression line.

The RMSE is a measure of how widespread these residues are. In other words, the RMSE tells you how concentrated the data is around the best-fit line. Smaller numbers are better, with zero being a perfect fit for the data. It is worth mentioning that both Rsquared and RMSE assess the accuracy of the model.

Taking Rsquared as the main metric for model performance analysis, the model that presented the best results was Model 3 (Decision Trees with Boosting) with Rsquared of 0.9372519 and RMSE of 129846.3.

